# ChatbotAI

Instead of paying a subscription, why not create your **own AI agent** with already trained models?  

This project is a **practice implementation of a mobile AI-powered chatbot**.  
It shows how to combine a simple iOS app, a Node.js message server, and an AI server (via [Ollama](https://ollama.ai/)) into a working system.  

The goal is to learn how to:  
- Build your own AI chatbot locally (no subscriptions needed)  
- Use real-time messaging with Socket.IO  
- Connect an iOS app to both a chat backend and an AI model  

The project is divided into three parts:

- **chatbot/** â†’ iOS mobile app (Xcode project)  
- **messages-server/** â†’ Node.js server for handling user messages  
- **ollama-server/** â†’ Local AI server powered by [Ollama](https://ollama.ai/)  
- **Screenshots/** â†’ App screenshots (1.PNG â†’ 10.PNG)  

---
## ğŸ“¦ Dependencies

- [MarkdownUI](https://github.com/gonzalezreal/MarkdownUI) â†’ Used for rendering Markdown content inside the iOS app.
- [Socket.IO](https://socket.io/) â†’ Real-time communication between clients and server.
- [Express.js](https://expressjs.com/) â†’ Web framework for Node.js message server.
- [Ollama](https://ollama.ai/) â†’ Local AI model runner (LLaMA2, Mistral, etc.).


## ğŸ“‚ Folder Structure

```
ChatbotAI/
â”‚
â”œâ”€â”€ chatbot/            # iOS Xcode project (mobile app)
â”‚
â”œâ”€â”€ messages-server/    # Node.js Express server for chat messages
â”‚   â””â”€â”€ server.js
â”‚
â”œâ”€â”€ ollama-server/      # Local AI server with Ollama
â”‚   â””â”€â”€ server.js
â”‚
â””â”€â”€ Screenshots/        # Screenshots (1.PNG â†’ 10.PNG)
```

---

## âš¡ Features

- Real-time **messaging** with WebSocket (Socket.IO)  
- AI **chatbot responses** using Ollama local models  
- **Mobile app** built in Swift (iOS)  
- Screenshot previews available in the `Screenshots/` folder  

---

## ğŸ›  Setup Instructions

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/yourusername/chatbotai.git
cd chatbotai
```

---

### 2ï¸âƒ£ Setup the Messaging Server (Node.js)

1. Navigate to the **messages-server** folder:
   ```bash
   cd messages-server
   ```
2. Install dependencies:
   ```bash
   npm install
   ```
3. Configure environment variables: create `.env` file
   ```env
   PORT=4000
   MONGO_URI=mongodb://localhost:27017/chatbotai
   ```
4. Start the server:
   ```bash
   npm start
   ```
5. âœ… Server will run on:  
   ```
   http://localhost:4000
   ```

---

### 3ï¸âƒ£ Setup the Ollama AI Server

#### Step 1. Install Ollama
- **macOS**:
  ```bash
  brew install ollama
  ```
- **Linux**:
  ```bash
  curl -fsSL https://ollama.com/install.sh | sh
  ```
- **Windows**:  
  Download from [Ollama Downloads](https://ollama.ai/download)  

Verify installation:
```bash
ollama --version
```

#### Step 2. Pull a Model
Example: download **llama2**
```bash
ollama pull llama2
```

#### Step 3. Run Ollama
```bash
ollama serve
```

Test with:
```bash
ollama run llama2
```

#### Step 4. Setup Ollama Express Server
Inside **ollama-server/** create `server.js`:

```js
const express = require("express");
const bodyParser = require("body-parser");
const fetch = require("node-fetch");

const app = express();
app.use(bodyParser.json());

app.post("/api/ask", async (req, res) => {
  const { prompt } = req.body;

  try {
    const response = await fetch("http://localhost:11434/api/generate", {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({ model: "llama2", prompt })
    });

    const data = await response.json();
    res.json(data);
  } catch (err) {
    res.status(500).json({ error: err.message });
  }
});

const PORT = process.env.PORT || 5000;
app.listen(PORT, () => console.log(`Ollama server running on port ${PORT}`));
```

Run the server:
```bash
cd ollama-server
npm install express body-parser node-fetch
node server.js
```

âœ… Server will run on:
```
http://localhost:5000
```

Test API:
```bash
curl -X POST http://localhost:5000/api/ask \
  -H "Content-Type: application/json" \
  -d '{"prompt": "Hello AI, how are you?"}'
```

---

### 4ï¸âƒ£ Setup the iOS App

1. Open `chatbot/ChatbotAI.xcodeproj` in Xcode  
2. Ensure deployment target is **iOS 13+**  
3. Update API base URLs in code:
   - `messages-server` â†’ `http://localhost:4000`
   - `ollama-server` â†’ `http://localhost:5000`
4. Build & Run on Simulator or iPhone  

---

## ğŸ“¸ Screenshots

Screenshots available in `Screenshots/` folder. Example:

| Screenshot 1 | Screenshot 2 | Screenshot 3 |
|--------------|--------------|--------------|
| ![](Screenshots/1.PNG) | ![](Screenshots/2.PNG) | ![](Screenshots/3.PNG) |

---

## ğŸš€ Running the Full System

1. Start **messages-server**  
   ```bash
   cd messages-server && npm start
   ```
2. Start **ollama-server**  
   ```bash
   cd ollama-server && node server.js
   ```
3. Run the **iOS app** from Xcode  
4. ğŸ‰ Chat with AI in real time  

---

## ğŸ”— API Endpoints

**Messages Server**  
- `POST /api/chatbot_messages/conversations` â†’ Create conversation  
- `GET /api/chatbot_messages/conversations?user_id=123` â†’ List conversations  
- `POST /api/chatbot_messages/messages` â†’ Save a message  
- `GET /api/chatbot_messages/messages?conversation_id=xxx` â†’ Fetch messages  

**Ollama Server**  
- `POST /api/ask` â†’ Ask the AI with a prompt  

---

## ğŸ§© Tech Stack

- **Frontend (iOS)**: Swift / UIKit  
- **Backend (Messages)**: Node.js, Express, MongoDB  
- **AI Engine**: Ollama + LLaMA2 / Mistral / Gemma  

---

## ğŸ“Œ Notes

- Ollama must be running before you start the **ollama-server**  
- MongoDB must be running before you start the **messages-server**  
- You can swap `llama2` with any supported Ollama model  

---

## ğŸ¤ Contributing
PRs welcome! Fork the repo and submit pull requests.  

---

## ğŸ“„ License
This project is licensed under the MIT License.  
